# Project 1 - Sparkify (Postgresql)
## Overview 
This project provide solution ETL data to analytics database(Postgresql).
It has been design relation database in **start schema**. Project build progress ETL (Extract, Transform and Load). Extract data from Json file and transform. After it insert(load) data to database.
Technologies: Python(pandas,psycopg2,Postgresql).
## Project Structure
1. **create_tables.py** drops and creates tables.
2. **etl.py** reads and processes files from song_data and log_data and loads them into your tables.
3. **sql_queries.py** contains sql query.
4. **test.ipynb** displays the first few rows of each table to let you check your database.
5. **etl.ipynb** this notebook contains detailed instructions on the ETL process for each of the tables.
6. **Song Dataset** The first dataset is a subset of real data from the Million Song Dataset. Each file is in JSON format and contains metadata about a song and the artist of that song. The files are partitioned by the first three letters of each song's track ID.
7. **Log Dataset** The second dataset consists of log files in JSON format generated by this event simulator based on the songs in the dataset above. These simulate activity logs from a music streaming app based on specified configurations.
## Schema
### Fact Table
- **songplays**(songplay_id, start_time, user_id, level, song_id, artist_id, session_id, location, user_agent).
### Dimension Table
- **users**(user_id, first_name, last_name, gender, level).
- **songs**(song_id, title, artist_id, year, duration).
- **artists**(artist_id, name, location, latitude, longitude).
- **time**(start_time, hour, day, week, month, year, weekday).
## How to use
- Install Python and Postgres
- Run command line **python create_table.py**(create database Sparkify)
- Run command line **python etl.py**